{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ab955fb",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "## GGR473 Lab 5 [part 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2036c23d",
   "metadata": {},
   "source": [
    "### Data\n",
    "Let's work with the same data we used in part 1: census tracts with aggregated features for AirBnB properties. \n",
    "\n",
    "For the lab we will aim to identify clusters in the data based on AirBnB price. However, you can think about how data may be clustered based on multiple features and/or spatial location. For example, you could try repeating the process using both price and number of bedrooms as features for clustering. \n",
    "\n",
    "I have also added a point file of the AirBnB locations to the data folder in case you'd like to test working with non-aggregated point data and different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ba79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may have seen an error when previously importing a shapefile whereby the projection library couldn't be found\n",
    "# The following code points to the PROJ library and should address the error\n",
    "os.environ['PROJ_LIB'] = '/path/to/env/share/proj'\n",
    "\n",
    "# Import shapefile and store data as geopandas geodataframe\n",
    "gdf = gpd.read_file(\"data/airbnbct23.shp\")\n",
    "print(gdf.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5368b626",
   "metadata": {},
   "source": [
    "### K-means clustering\n",
    "\n",
    "K-means clustering is an unsupervised machine learning algorithm used for partitioning a dataset into K distinct clusters. It is commonly used to segment data and identify patterns and anomalies. \n",
    "\n",
    "In our example, we can identify which areas have similar pricing characteristics. To do this we will again use the [sci-kit learn](https://scikit-learn.org/stable/index.html) library, specifically the [KMeans](https://scikit-learn.org/stable/modules/clustering.html#k-means) module.\n",
    "\n",
    "**Aim:** Group census tracts based on Airbnb price into distinct clusters\n",
    "\n",
    "- pricemean = mean AirBnB price for census tract\n",
    "\n",
    "For the following example, I choose k=4 clusters to identify clear groups of high and low pricing. It's possible to choose the number of clusters based on your own subject knowledge, however, there are also technical approaches to selecting k. You may like to explore options such as [elbow plots](https://www.geeksforgeeks.org/elbow-method-for-optimal-value-of-k-in-kmeans/) for finding the optimal number of clusters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c797b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Select relevant feature(s) for clustering\n",
    "X = gdf[['pricemean']] #To cluster based on multiple features (e.g., price and no. bedroom) use [['pricemean', 'bedrmsmed']] \n",
    "\n",
    "# Initialize model by setting number of clusters\n",
    "km4 = KMeans(n_clusters=4)\n",
    "\n",
    "# Fit the model to the relevant features\n",
    "km4clusters = km4.fit_predict(X)  # fit_predict() fits the model and assigns cluster labels (e.g., 0, 1, 2, 3) which are helpful for grouping later\n",
    "\n",
    "# Add cluster labels to the original DataFrame\n",
    "gdf['km4clusters'] = km4clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa26bf",
   "metadata": {},
   "source": [
    "The above code places a centroid seed (initial cluster centres) randomly and assigns nearest data points to the centroid. For each cluster, the algorithm recalculates the centroids based on the mean of all of its assigned data points and repositions the centroid accordingly. This process happens iteratively until a point of convergence or the maximum number of iterations is reached. \n",
    "\n",
    "You may see a warning for `n_init` above. `n_init` is the maximum number of iterations and is currently set to 10. In a future version of the KMeans module, this will change from 10 to 'auto'.\n",
    "\n",
    "Now let's use [matplot.pyplot](https://matplotlib.org/3.5.3/api/_as_gen/matplotlib.pyplot.html) to take a look spatially at which neighbourhoods were assigned to each cluster based on AirBnB price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc93ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axes\n",
    "f, ax = plt.subplots(1, figsize=(9, 9)) # f is the top level container for our plot and ax is the area where data are plotted\n",
    "\n",
    "# Extract clusters from new column 'km4clusters' and show on map\n",
    "gdf.plot(column='km4clusters', categorical=True, legend=True, ax=ax)\n",
    "\n",
    "# Turn off axes lines and values\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Add title\n",
    "plt.title('AirBnb price classification for Toronto')\n",
    "\n",
    "# Display the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d64a78",
   "metadata": {},
   "source": [
    "The map above shows a pattern: there is a class at the core and north of the city (cluster number 3), two sporadic clusters (1 and 2), and a more suburban cluster (0).\n",
    "\n",
    "This gives us an insight into the geographical structure, but does not tell us much about what are the defining elements of these groups. To do that, let's look at the characteristics of the clusters and visualize the mean of the different AirBnB prices for each.\n",
    "\n",
    "If working with multiple variables, you could stack the different variables on the bar plot to view their proportions across groups. Some standardisation may be helpful here. For example, including a mean price of $200 and a median of 2 bedrooms in the same bar would make it difficult to view how clusters have been divided up based on high price, low number of bedrooms etc. as price would dominate the display. Instead displaying standardised values (e.g., [z-scores](https://wikitekkee.com/how-to-calculate-z-score-in-python/) where z = (X-mean)/std) would make it easier to compare variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data points by cluster label and calculate mean for each cluster\n",
    "cluster_means = gdf.groupby('km4clusters')[['pricemean']].mean()\n",
    "\n",
    "\n",
    "# Create a horizontal bar plot for cluster means\n",
    "f, ax = plt.subplots(1, figsize=(18, 9))\n",
    "cluster_means.plot(kind='barh', stacked=True, ax=ax)\n",
    "\n",
    "# Add labels, title and legend\n",
    "plt.xlabel('Mean Price')\n",
    "plt.ylabel('Cluster')\n",
    "plt.title('Cluster means for AirBnB price')\n",
    "plt.legend(['Mean price for AirBnB'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d215ff4",
   "metadata": {},
   "source": [
    "We can see that cluster 1 is based on high prices and cluster 0 on low prices. Based on the map, is this what you would expect to see? It seems there are some interesting outliers for high prices.\n",
    "\n",
    "So far our clustering has been based purely on the price variable. Let's incorporate spatial relationships by including a spatial weight in the model.\n",
    "\n",
    "### Spatial autocorrelation\n",
    "First check to see if spatial autocorrelation exists using Moran's I statistic (a global measure of spatial autocorrelation). This provides good grounds for including spatial weights in your model or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda.moran import Moran\n",
    "\n",
    "# Generate spatial weights (using Queen contiguity in this case)\n",
    "w = Queen.from_dataframe(gdf)\n",
    "\n",
    "# Calculate Moran's I to see if spatial autocorrelation in price exists\n",
    "moran = Moran(gdf['pricemean'], w)\n",
    "\n",
    "# Print Moran's I statistic and p-value\n",
    "print(\"Moran's I:\", moran.I)\n",
    "print(\"P-value:\", moran.p_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd019389",
   "metadata": {},
   "source": [
    "It seems there is one census tract that doesn't have any neighbours based on Queen contiguity! I'm sure you can figure out which census tract this is. As a result, it was excluded from the calcuation. \n",
    "\n",
    "Otherwise, a significant positive Moran's I statistic (albeit quite a small one) suggests there is postive spatial autocorrelation in price i.e., similar prive values tend to cluster spatially.\n",
    "\n",
    "We can also also use a Local Moran's i statistic (similar to Lab 4) to see where clustering of prices occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f06a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda.moran import Moran_Local\n",
    "from splot.esda import moran_scatterplot, plot_local_autocorrelation\n",
    "\n",
    "# Calculate local Moran's I\n",
    "moran_loc = Moran_Local(gdf['pricemean'], w)\n",
    "\n",
    "# Plot Moran scatterplot\n",
    "fig, ax = moran_scatterplot(moran_loc, p=0.05)\n",
    "plt.show()\n",
    "\n",
    "# Plot Local Moran's I Map\n",
    "plot_local_autocorrelation(moran_loc, gdf, 'pricemean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a026a915",
   "metadata": {},
   "source": [
    "It's clear there's some clustering of high values and low values in certain locations. This looks a little different to where we see census tracts that have been grouped due to high prices. \n",
    "\n",
    "### Spatial K-means clustering\n",
    "Let's see if spatial autocorrelation affects our model by adding spatial weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b193f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libpysal.weights import Queen\n",
    "\n",
    "# Convert the spatial weights matrix to a numpy array so it can be appended to your feature set of price values\n",
    "w_matrix = w.full()[0]\n",
    "\n",
    "# Append spatial weights\n",
    "X_with_weights = np.hstack((X.values, w_matrix))\n",
    "\n",
    "# Perform K-Means clustering on the extended dataset\n",
    "skm4clusters = km4.fit_predict(X_with_weights)\n",
    "\n",
    "\n",
    "# Add cluster labels to geodaraframe\n",
    "gdf['skm4clusters'] = skm4clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa35def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two subplots side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot the clusters from K-Means on the first subplot (axes[0])\n",
    "gdf.plot(column='km4clusters', categorical=True, legend=True, ax=axes[0])\n",
    "\n",
    "# Plot the clusters from Spatial K-Means on the second subplot (axes[1])\n",
    "gdf.plot(column='skm4clusters', categorical=True, legend=True, ax=axes[1])\n",
    "\n",
    "# Set titles for plots\n",
    "axes[0].set_title('K-Means clustering')\n",
    "axes[1].set_title('Spatial K-Means clustering')\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bff986",
   "metadata": {},
   "source": [
    "The outputs are similar but by including spatial weights, the census tracts groupings has changed slightly (e.g., in East Scarborough). You may like to take time exploring the cluster means with bar plots. Note that the labels may not align completely but can be [updated.](https://www.digitalocean.com/community/tutorials/update-rows-and-columns-python-pandas) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef166097",
   "metadata": {},
   "source": [
    "Once you have worked through the notebook and feel happy with the concepts, export your notebook by selection File > Print Preview > Save as PDF.\n",
    "\n",
    "Upload your PDF to Part 2 of the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e155079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
