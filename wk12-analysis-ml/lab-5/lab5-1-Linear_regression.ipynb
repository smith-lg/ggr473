{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad3f8cf",
   "metadata": {},
   "source": [
    "# Linear and spatial regression\n",
    "## GGR473 Lab 5 [part 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b00024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5cf7e0",
   "metadata": {},
   "source": [
    "### Data\n",
    "You will be using data that represent the count, density, and aggregated characteristics of AirBnB properties within census tracts in Toronto. \n",
    "\n",
    "Data have been formatted and prepared for the lab, however, you can explore the data sources here:\n",
    "\n",
    "- http://insideairbnb.com/get-the-data/\n",
    "- https://datacentre.chass.utoronto.ca/census/\n",
    "\n",
    "Census data are from 2021 and AirBnB listings from 2023. The temporal mismatch in the data, as well as the use of aggregated area-level data for analysis highlight key limitations in relation to data quality,  ecological fallacy, and the modifiable areal unit problem (MAUP). Note that these would make strong discussion points for the group project report.\n",
    "\n",
    "While we will be importing data from a shapefile, consider how this could also be queried from a database (as shown in lab5-0_accessDBdata.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93043b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import shapefile and store data as geopandas geodataframe\n",
    "gdf = gpd.read_file(\"data/airbnbct23.shp\")\n",
    "\n",
    "# Explore the geodataframe by displaying the top ten rows and checking column names and data types\n",
    "print(gdf.head())\n",
    "print(gdf.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525e91bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data's geometries by plotting them\n",
    "gdf.plot()\n",
    "plt.title('Spatial plot of geometries')\n",
    "plt.show()\n",
    "\n",
    "# Check the distribution of an attribute with a histogram\n",
    "gdf['incomemed'].plot(kind='hist', bins=20)\n",
    "plt.title('Histogram of neighbourhood median income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeff464",
   "metadata": {},
   "source": [
    "### Simple linear regression\n",
    "Linear regression enables the relationship between two or more variables to be modelled. Models assume a linear relationship between the independent variables (explanatory, predictor or input features) and the dependent variable (target outcome). The model estimates the coefficients that best fit the data to assess existing relationships and may be applied predict the target variable.\n",
    "\n",
    "**Ordinary Least Squares (OLS)** is a commonly method used to estimate the parameters (slope coefficients and intercept) of a linear regression model. It determines the parameters that best fit the observed data by minimizing the sum of the squared differences between the predicted and actual values.\n",
    "\n",
    "Let's start with a **simple** OLS model that estimates the relationship between two variables: income (independent variable) and AirBnB density (dependent variable). We will use the [statsmodels](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html) library.\n",
    "\n",
    "- incomemed: median income per census tract\n",
    "- airbnbdens: number of AirBnB properties per square km within census tract\n",
    "\n",
    "We can see from the histogram plot above that there are a small number of census tracts with an income of zero. As a census tract with an income of zero doesn't make sense, we will remove for the analysis for simplicity. However, you might want to think about how these missing values could be imputed based on a weighted average of neighbouring census tracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf[gdf['incomemed'] > 0]\n",
    "\n",
    "# Access the income and price fields and set as variables\n",
    "X = gdf['incomemed'] # independent variable\n",
    "y = gdf['airbnbdens'] # dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccefcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a simple linear regression model\n",
    "X = sm.add_constant(X)  # Add a constant term for intercept\n",
    "m1 = sm.OLS(y, X).fit() \n",
    "\n",
    "# Print the regression results\n",
    "print(m1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f995a138",
   "metadata": {},
   "source": [
    "A positive co-efficient and significant p-value (<0.05) suggests that an increase in income is associated with an increase in the price of AirBnB properties.\n",
    "\n",
    "**R-squared** represents the proportion of variance (or spread of values) in y that is explained by X in the model (typically between 0 and 1). A low R-squared of 0.046 suggests that the model does not effectively explain much of the variability observed in the dependent variable and the model is currently not a great fit for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b91942d",
   "metadata": {},
   "source": [
    "### Multiple regression\n",
    "Including multiple variables in regression analysis offers several advantages that contribute to enhancing the explanation of relationships and improving model fit.\n",
    "\n",
    "There are many ways to select additional variables (e.g., by checking for multicolinearity or by using stepwise selection). However, for simplicity we will draw on our prior knowledge and include variables that we expect to influence the dependent variable, airbnb density. \n",
    "\n",
    "Let's add population density and household size into our model:\n",
    "\n",
    "- popndens21: population density per census tract\n",
    "- hhsizemean: mean household size per census tract\n",
    "\n",
    "\n",
    "Note we do not have data on all potential influences, such as housing type or amenities. So while we control for confounding by variables included in the model, we do not control for all potential confounders. This unmeasured confounding is termed residual confounding and can bias effect estimates. Another good talking point for the group project!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c531e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update X to include multiple independent variables\n",
    "X = gdf[['incomemed', 'popnden21', 'hhsizemean']]\n",
    "\n",
    "# Re-run the regression model\n",
    "X2 = sm.add_constant(X)  # Add a constant term for intercept\n",
    "m2 = sm.OLS(y, X2).fit() \n",
    "\n",
    "print(m2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174add2c",
   "metadata": {},
   "source": [
    "Notice what has happened to the r-squared value. Can you explain the effects shown for each independent variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53b4091",
   "metadata": {},
   "source": [
    "### Machine learning\n",
    "[Scikit-learn](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) is a great library to use for doing machine learning in Python. Though we will use it for linear regression, the library is worth exploring for its many options for data preparation, exploratory data analysis (EDA), classification, regression, and clustering!\n",
    "\n",
    "Training sets are used to facilitate model training and test sets are used to assess model performance.\n",
    "Below, the data are randomly divided into training and test sets using a fixed proportion. **test_size=0.2** specifies that 20% of the data will be allocated to the test set and the remaining 80% will be assigned to the training set.\n",
    "\n",
    "Splitting data into training and test sets allows for model performance to be evaluated on unseen data. This  helps to  estimate how well the model might perform on new, unseen observations. In this example, this could be for census tracts where there are no data available for AirBnb listings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39334848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Linear Regression model\n",
    "m3 = LinearRegression()\n",
    "m3.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_linear = m3.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Coefficients:\", m3.coef_)\n",
    "print(\"Intercept:\", m3.intercept_)\n",
    "\n",
    "m3_mse = mean_squared_error(y_test, y_pred_linear)\n",
    "print(f\"Linear Regression Model 3 MSE: {m3_mse}\")\n",
    "print(\"R-squared:\", r2_score(y_test, y_pred_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa63c9",
   "metadata": {},
   "source": [
    "The Mean Squared Error (MSE) of a machine learning linear regression model provides insight into the model's predictive performance. A smaller MSE indicates that, on average, the model's predictions are closer to the actual values in the test set.\n",
    "\n",
    "Adding/removing variables or creating new variables that better explain relationships in the data are simple approaches that can improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de447495",
   "metadata": {},
   "source": [
    "### Spatial regression\n",
    "So far we have worked with linear regression models without any consideration for the spatial structure of our data. Intuitively, the price of AirBnBs is likely influenced by spatial factors such as the proximity to amenities and transport links.\n",
    "\n",
    "To incorporate spatial weights into our model that account for neighbouring data, we can use the spreg module in [PySAL](https://pysal.org/). Spreg implements a standard OLS routine, but is particularly well suited for regressions on spatial data.\n",
    "\n",
    "Below we construct a spatial weights matrix using Queen contiguity and add it to the model. The Queen contiguity is one approach to define spatial relationships based on shared boundaries (common edges or vertices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e235c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import libpysal\n",
    "from libpysal.weights import Queen\n",
    "from esda.moran import Moran\n",
    "from spreg import OLS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc9597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gdf[['incomemed', 'popnden21', 'hhsizemean']]\n",
    "\n",
    "# Convert gdf to numpy array (required for spreg)\n",
    "X_array = X.to_numpy()\n",
    "y_array = y.to_numpy()\n",
    "\n",
    "# Construct spatial weights using queen contiguity\n",
    "w = Queen.from_dataframe(gdf)\n",
    "\n",
    "# Calculating spatial autocorrelation\n",
    "moran = Moran(gdf['airbnbdens'], w)\n",
    "print(f\"Moran's I: {moran.I}\")\n",
    "\n",
    "# Run Spatial OLS Model with multiple independent variables\n",
    "m4 = OLS(y_array, X_array, w=w, name_y='airbnbdens', name_x=['incomemed', 'popnden21', 'hhsizemean'], name_ds='airbnb-gdf', name_w='Queen', spat_diag=True)\n",
    "#results_spatial_ols = model_spatial_ols.fit()\n",
    "\n",
    "# Print regression results\n",
    "print(m4.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fdb6fb",
   "metadata": {},
   "source": [
    "Above we tested for global sptial autocorrelation using the Moran's I statistic (values range from -1 to 1). A value of 0.656 indicates a relatively strong positive spatial autocorrelation for AirBnB density. While this suggests neighboring census tracts tend to have similar values for the AirBnB density, the coefficients of the spatial regression model remain largely unchanged. The **spatial effects** of our independent variables may not therefore be strongly associated the dependent variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27efcadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MSE manually for Model 2 (multiple OLS model)\n",
    "residuals = m2.resid\n",
    "m2_mse = (residuals ** 2).mean()\n",
    "print(f\"Linear Regression Model 2 MSE: {m2_mse}\")\n",
    "\n",
    "m4_mse = mean_squared_error(y, m4.predy)\n",
    "print(f\"Linear Regression Model 4 MSE: {m3_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75845df",
   "metadata": {},
   "source": [
    "It looks like the MSE improves by adding the spatial weight matrix, despite the coefficients and significance remaining the same. This could mean the model's predictive accuracy has been enhanced after accounting for spatial relationships and the addition of spatial information might help capture some of the unexplained variation in the dependent variable that was previously attributed to random error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f4b18",
   "metadata": {},
   "source": [
    "Once you have completed the lab, export your notebook by selection File > Print Preview > Save as PD.\n",
    "\n",
    "Upload your PDF to Part 1 of the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f164ec7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
